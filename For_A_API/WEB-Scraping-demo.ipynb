{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e25b70-93c6-484e-89c9-c281ae6be97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01b5748c-1a14-4c0a-a3e0-9420e9f072bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed15b12-bdf9-4093-9745-4e46b8658dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02da3df9-564a-4e9e-9eb5-cc04c74223ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c90a94ff-3ce5-4a65-8136-a9f8d2e36554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7fa844-a7bf-48d9-9d25-f190ab6628f9",
   "metadata": {},
   "source": [
    "# if response code is 403\n",
    "#### headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'} \n",
    "#### -requests.get('url',headers=headers).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df63af79-b12a-4398-827a-faf4e2ba4450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection error occurred: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    }
   ],
   "source": [
    "from requests.exceptions import ConnectionError\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'}\n",
    "\n",
    "try:\n",
    "    response = requests.get('https://www.ambitionbox.com/list-of-companies?page=1', headers=headers, timeout=20)\n",
    "    print(response.text)\n",
    "except ConnectionError as e:\n",
    "    print(f\"Connection error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a3a195-0d60-4a42-bc53-9e05a6775846",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(webpage,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a80254f-a2f1-4fed-b050-7b7f4b1fb231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


##    Added MASUD ALAM  write version
import requests
from bs4 import BeautifulSoup

url = "https://books.toscrape.com"
headers = {"User-Agent": "Mozilla/5.0"}

response = requests.get(url, headers=headers)

print("Status code:", response.status_code)
print("Length of content:", len(response.text))

soup = BeautifulSoup(response.text, 'html.parser')

# Print a snippet of HTML (first 500 chars)
print(response.text[:500])

# Find all tables
all_tables = soup.find_all('table')
print(f"Total tables found: {len(all_tables)}")

# Find tables by class "wikitable sortable"
tables = soup.find_all('table', {'class': 'wikitable sortable'})
print(f"Tables with class 'wikitable sortable': {len(tables)}")

# List class attributes of all tables to check what classes are used
for i, table in enumerate(all_tables[:5]):  # check first 5 tables
    print(f"Table {i} classes: {table.get('class')}")   

#########################OUTPUT##################################
Status code: 200
Length of content: 51294
<!DOCTYPE html>
<!--[if lt IE 7]>      <html lang="en-us" class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html lang="en-us" class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html lang="en-us" class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html lang="en-us" class="no-js"> <!--<![endif]-->
    <head>
        <title>
    All products | Books to Scrape - Sandbox
</title>

        <meta http-equiv="content-type" content="text/html; charset=UTF-8" /
Total tables found: 0
Tables with class 'wikitable sortable': 0
#####################################################################################
books = soup.find_all('article', class_='product_pod')

for book in books[:5]:  # first 5 books
    title = book.h3.a['title']
    price = book.find('p', class_='price_color').text
    print(f"Title: {title}, Price: {price}")
  ***********************************************OUTPUT**************************************
Title: A Light in the Attic, Price: Â£51.77
Title: Tipping the Velvet, Price: Â£53.74
Title: Soumission, Price: Â£50.10
Title: Sharp Objects, Price: Â£47.82
Title: Sapiens: A Brief History of Humankind, Price: Â£54.23
